Because the measurable time and length scale of biological experiments are usually larger than those of the system, the dynamics in the system can only be measured indirectly. To get a more precise insight into the specific processes, molecular dynamics simulations (MD) are a suitable tool.\\
In the following section, the main concepts of MD and characteristics of the used models are outlined with a special focus on the \martini{} force field. An exhaustive exploration of these methods, however, would be outside the scope of this thesis. Because \gromacs{} (GROningen MAchine for Chemical Simulations) \autocites{gromacs1, gromacsManual} was used as MD engine in this thesis, the following explanations refer to \gromacs{} conventions and features. 
\subsection{The physics of MD}
In MD, atoms are modelled as solid beads, which comprise the nucleus as well as the electron shell, and follow classical equations of motion. Due to this implicit treatment of electrons, quantum mechanical (QM) effects, such as excitation or electron transfer processes, are not accessible in MD. However, the beads are parametrized by effective parameters motivated by QM or experiments \autocite[p. 127-128]{greenBook}.\\
Newton's equation of motion can be turned into two first order differential equations:
\begin{align}
	\label{eq:eq_of_mot_first_order}
	\frac{\diff \vec{r}_i}{\diff t} &= \vec{v}_i \\
	m_i \frac{\diff \vec{v}_i}{\diff t} &= \vec{F}_{i},
\end{align}
which can be integrated numerically with e.g. Leapfrog- or Verlet integration scheme. Both are time reversible and symplectic, which ensures a small long-term error in energy conservation \autocite[p. 72-74]{UnderstandingMD}. The force acting on particle $i$ is given by the gradient of the potential $V$ at its position. In MD, bonded and non-bonded interactions contribute to this potential, but also external forces can be applied:
\begin{align}
	\vec{F}_i = - \frac{\partial V}{\partial \vec{r}_i} = - \frac{\partial}{\partial \vec{r}_i} \left(V_\text{bonded} + V_\text{non-bonded} + V_\text{external}\right).
\end{align}
\subsubsection{Bonded interactions}
Bonded interactions act intramolecularly and describe chemical bonds. They can occur between two, three or four particles and refer to bond stretching, bending and torsion respectively. An illustration can be found in \autoref{md:fig_bonds}.\\
\\
Deviations of the bond length $r$ from an equilibrium distance $r_0$ result in potential energy, which is usually described by a harmonic oscillator with the force constant $k_\text{dist}$:
\begin{align}
V_{\text{dist, bond }i} = \frac{k_{\text{dist}}}{2}\left( r - r_{0} \right)^{2}.
\end{align}
For larger deviations, a Morse potential, assuming an exponential decay of the potential energy, is more precise, but has a much higher computational cost.\\
\\
Bending of a chemical bond refers to deviations of the angle $\theta$ between three bonded partners from an equilibrium angle $\theta_0$. The resulting potential is usually described by a harmonic oscillator as well:
\begin{equation}
V_\text{angle} = \frac{k_\text{angle}}{2}\left( \theta - \theta_0 \right)^{2}.
\end{equation}
The dihedral angle describes the angle between two planes, each going through three beads, and having two beads in common. Therefore, it can be understood as a torsion angle, but can also be used to preserve plane rings and the chirality of four particle groups. The resulting potential energy is usually approximated with a periodic approach:
\begin{equation}
V_{\text{dihedral, periodic}} = \frac{k_\text{dihedral}}{2}\left(1 + \cos\left(n \phi - \phi_0 \right)\right),
\end{equation}
where $k_\text{dihedral}$ describes the energy barrier for turning the dihedral angle, $n$ the number of minima in the energy function (multiplicity) and $\phi_0$ a phase factor \autocite[p. 71-83]{gromacsManual}.
%
%
%
\begin{figure}
	\subcaptionbox{\label{md:fig_bonds}}[0.5\textwidth]{
		\includegraphics[height=3cm]{figures/introduction/fig_bonds}
		\vspace{1cm}
	}\hfill%
	\subcaptionbox{\label{md:fig_pot}}[6cm]{
		\includegraphics[height=6cm]{figures/introduction/fig_potentials}
	}%
	\nicecaption{Interactions in MD}{(\subref{md:fig_bonds}): Illustration of bonded interactions: bond stretching ($r$), bending ($\theta$) and dihedral angle $\Phi$ (angle between blue and green plane). (\subref{md:fig_pot}): schematic course of contributing potentials}
	\label{md:figs}
\end{figure}
%
%
%
\subsubsection{Non-bonded interactions}
Non-bonded interactions are present between all atoms in the system and act pairwise. In MD, Pauli repulsion, van der Waals (vdW) forces and electrostatic forces are taken into account.
The Lennard-Jones potential combines Pauli repulsion ($r^{-12}$ term) and the vdW force ($r^{-6}$ term):
\begin{equation}
V_\text{Lennard-Jones} = \sum_{\text{non-bonded pairs i,j}} 4 \epsilon\left(\left(\frac{\sigma}{r_{ij}}\right)^{12} - \left(\frac{\sigma}{r_{ij}}\right)^6\right).
\end{equation}
$\epsilon$ is related to the potential depth and $\sigma$ to the potential range (see \autoref{md:fig_pot}).\\
\\
The Coulomb potential is given by
\begin{equation}
V_\text{Coulomb} = \frac{q_1 q_2}{4 \pi \epsilon_0 \epsilon_r r},
\end{equation}
where $q_1$, $q_2$ are the (partial) charges of the interacting particles, $r$ their distance and $\epsilon_r$ the relative dielectric constant \autocite[p. 65-71]{gromacsManual}.\\
\\
In general, non-bonded interactions act between all atoms in the system implying a very large computational cost.\\
The easiest solution for this problem is to use a cut-off radius $r_c$. Particles beyond this radius are not taken into account. This can be implemented very efficiently with a Verlet neighbour lists. For each particle, a neighbour list is created, which contains all particles inside a second radius $r_v$ with $r_v > r_c$. This reduces the number of distance calculations a lot. The lists are updated if the maximal displacement in the system is larger than $r_v - r_c$.  The application of a cut-off radius is suitable especially for Lennard-Jones potential, as it decays very rapidly and $r_c$ can be chosen very small \autocite[p. 144]{greenBook}.\\
Because the electrostatic potential is proportional to $1/r$, the use of a cut-off radius would lead to large jumps in the potential. That is why long range interactions have to be considered, which can be effectively done with Particle Mesh Ewald (PME) summation \autocite{pme}. Particle mesh methods in general split up the electrostatic potential into a short-range and a long-range part via a switching function. The short-range part can be calculated with a small cut-off radius in real space. The long-range part, however, is calculated by solving the Poisson equation of the actual charge distribution, for which a discrete grid (mesh) is used. In contrast to other particle mesh methods, this grid is transformed to Fourier space in PME with FFT techniques. Here, the solution of the Poisson equation is a sum over the grid points. Afterwards, the potential can be transformed back into real space. The use of PME requires of course periodic boundary conditions, which are described in \autoref{subsec:pbc} \autocite[p. 246-251]{greenBook}.
\subsubsection{External forces}
With \gromacs{}, it is possible to perform pulling forces onto groups of atoms in the system. In this thesis, pulling was used to bias distances between groups. For this, \gromacs{} provides an option to apply an umbrella potential to two groups, which yields a force proportional to the deviation of the distance between the groups from a reference distance. The force can be applied on one or two spatial dimensions only or along a predefined vector and the reference distance can change in time  \autocite[p. 154-159]{gromacsManual}.
\subsection{Force fields}
The parameters for the potentials described above are provided by force fields. There is a wide range of force fields, which are optimized for different application fields. In this thesis, two different ones, \charmm{} and \martini{}, are employed.\\
\\
Force fields map atoms (particles in physical system) onto beads (particles used in the simulation). This mapping can take the chemical environment of the particle into account, but can also neglect details by e.g. mapping several atoms onto one bead (coarse graining).\\
Force fields can be distinguished in non-polarizable and polarizable force fields. The latter offer the possibility to model electronic polarization, e.g. with additional shell beads. Orientational and geometric polarisation are also accessible with non-polarizable force fields since they only rely on partial charges \autocite[p. 215-217]{greenBook}. Both, \martini{} and \charmm{}, are non-polarizable force fields.\\  
Force fields not only define the atom types and their properties, but also all parameters for the calculation of the potential, namely force constants, equilibrium distances, etc. Therefore, force fields define the physics of the system.
\subsubsection{All-atom and the \charmm{} force field}
\charmm{} \autocites{charmm36_protein}{charmm36_lipids} (C36) is part of the CHARMM (\textit{Chemistry at HARvard Macromolecular Mechanics}) MD engine and was published in 2010. In C36, all atoms are considered (all-atom force field). Parameters were mainly optimized to structural experimental data, such as nuclear magnetic resonance (NMR) or X-ray data, but also QM and semi-empirical QM calculations were used (e.g. for dihedral angles of the sidechains of proteins \autocite{charmm36_protein} and partial charges of lipids \autocite{charmm36_lipids}).\\
All simulations for optimizing have been done with a time step of $2\,\si{\femto\second}$. Therefore, very detailed dynamics are still included in the simulations.\\
\\
For all simulations, the TIP3P water model \autocite{tip3p} was used, which was also used in the parametrisation of C36. Here, each water molecule is modelled with three partially charged beads.
\subsubsection{Coarse graining and the \martini{} force field}
\label{subsub:coarsegraining}
The \martini{} force field \autocites{martini}{martini22}{martini22_lipids} is one of the most famous coarse-graining force fields. Most beads are constituted of four heavy atoms (see \autoref{md:martinimapping}), which implies a loss of chemical information, but also an enormous reduction of computational cost. With this approach much larger time- and spatial scales are accessible for MD simulations.\\
The parametrisation of \martini{} is mainly based on reproducing free energies, e.g. partitioning free energies and dimerization free energies of amino acid side chain analogues. For lipids, also thermodynamic properties, such as area per lipid, have been considered. The parameters were optimized with a time step of $20\,\si{\femto\second}$ up to $30\,\si{\femto\second}$ \autocites{martini22}{martini22_lipids}.\\
%
%
%
\begin{figure}[b]
	\centering
	\includegraphics[width=.5\textwidth]{figures/introduction/fig_martini_mapping}
	\nicecaption{\martini{} bead mapping}{\martini{} structure of \pip{} with underlying atomistic structure. Four heavy atoms are mapped to one \martini{} bead. The colour indicates the bead type.}
	\label{md:martinimapping}
\end{figure}
%
%
%
\\
There are several side effects of coarse graining. Due to the mapping of four atoms to one bead, different atomistic structures can end up in the same \martini{} structures, which can be problematic e.g. for lipid tails. Also the secondary structure of proteins is affected as it becomes less stable in coarse-grained models. Therefore, it has to be constrained with elastic networks (additional bonds between backbone beads) and cannot change during the simulation \autocite{martini22_check}.\\
The decrease in degrees of freedom in the system also smooths the energy surface in coarse-grained models. Because smaller local irregularities in the energy surface, which would slow down the evolution of the system, are smoothed out, coarse graining speeds up the dynamics of the system. The speed-up factor is not constant, but can be relatively well approximated by factor of $4$ (obtained in most diffusion simulations) \autocites{martini22_check}{martini}.\\
Coarse graining also has an effect on the entropy and the temperature dependency of the system. In NpT ensembles, the Gibbs free energy $G$ is given by
\begin{equation}
G = H - T S,
\end{equation}
where $S$ is the entropy and $H$ the enthalpy. Due to a lower number of degrees of freedom in coarse grained systems, the configurational entropy is reduced. Because \martini{} is tuned to free energy calculations, this implies also a reduction of the enthalpy. The temperature dependency is therefore systematically biased \autocite{martini22_check}.\\ 
\\
Consistently with the four to one mapping, solvent beads in \martini{} represent four water molecules. The \martini{} water has a freezing temperature of ca. $300\,\si{\kelvin}$ and the freezing process is irreversible. Therefore, antifreeze beads were introduced, which have a larger $\sigma_\text{LJ}$ regarding interactions with normal solvent beads. By inserting these antifreeze beads, the lattice conformation is disturbed and the freezing temperature reduced \autocite{martini}.\\
In contrast to water, the solvent beads are not (orientationally) polarizable. For this reason, electrostatic screening has to be treated implicitly, which is done by a relative dielectric constant $\epsilon_r = 15$. However, this approximation fails near polar beads, resulting in an underestimation of the interaction strength between polar beads \autocite{martini22_check}. To forgo implicit screening, a polarizable water model was introduced in \martini{}, which is denoted as PW in the following. In PW, one water bead consists of three beads, two of them carrying charges. This model enables orientational polarizability and decreases the freezing point as well.
This, however, comes with a higher computational cost \autocite{polarizableMartini}.\\
\\
As reviewed by \textcite{martini22_check}, \martini{} has been already used to study protein-membrane interactions as well as protein oligomerization on membranes. Also changes in tertiary structure have been addressed using \martini{}.
\subsection{External constrains}
\subsubsection{Periodic boundary conditions}
\label{subsec:pbc}
Because the simulation of an open system is not possible, boundary conditions have to be considered. Closed boundaries often lead to surface interaction artefacts and are therefore in most cases not suitable for MD simulation. That is why usually periodic boundary conditions (PBC) are used.\\
To use PBC, the shape of the simulation box has to have a space filling geometry (e.g. rectangular or rhombic dodecahedron). With periodic boundary conditions, images of the simulation box are repeated in every direction. If a particle leaves the simulation box, its periodic image is coming in from the opposite side. In that way, the number of particles is kept constant while surface interactions are avoided.\\
A particle interacts only with the nearest image of another particle, which means that particles near boundaries can interact with periodic images of other particles instead of the real particle. Moreover, molecules can have long-range interactions with their own periodic images, which leads to artefacts and has to be considered when choosing the size of the simulation box \autocite[p. 141-142]{greenBook}.
%It is generally thought, that PBC only have small or no effects on equilibrium properties or structures of fluids, but known problems are the absence of long wavelength fluctuations (e.g. in phase transitions) or the violation of angular momentum conversation .
\subsubsection{Thermostats}
Integration schemes in MD are designed to conserve the energy of a system. However, in real biological systems, not the energy but rather the temperature is kept constant. This can be achieved with thermostats. For the simulations in this thesis, the Berendsen thermostat \autocite{berendsen} (BT), the Parrinello-Bussi thermostat \autocite{parinelloBussi} (PBT) and the Nos√®-Hoover thermostat \autocites{nosehooverthermo}{nosehooverthermo2} (NHT) were used. BT couples the system to a heat bath by rescaling the velocities of the particles, which results in an exponential decay of temperature deviations. The coupling strength is given by the time constant of this decay. The rescaling involves a transfer of kinetic energy from internal degrees of freedom to translational and rotational kinetic energy of the system's COM \autocite{velRescaleSucks}. In order to prevent this transfer, PBT extends BT by a stochastic term. Both BT and PBT are useful for equilibration runs or non-equilibrium MD simulations, as they are stable upon large deviations \autocites{berendsen}[p. 31]{gromacsManual}.\\
On the other hand, NHT extends the Hamiltonian of the system by a friction term representing a heat bath. The friction parameter follows a differential equation depending on the temperature deviation. This ansatz samples the phase space more accurately, making NHT suitable for production runs. However, NHT gets unstable for large deviations \autocite[p. 32-33]{gromacsManual}.\\
\\
Often, groups are coupled to independent thermostats. This is helpful because the heat exchange between for instance proteins and solvents is often not correct. Therefore, proteins would cool down and the solvent would heat up \autocite[p. 34]{gromacsManual}.
\subsubsection{Barostats}
In biological systems, often not the volume but the pressure is constant, which can be achieved in MD with a barostat. For equilibration runs, the Berendsen barostat \autocite{berendsen} was used, which couples the system, analogously to the BT, to an external pressure by rescaling the positions of the particles \autocite[p. 36]{gromacsManual}. For production runs, the Parinello-Rahman barostat \autocites{parinelloBarostat}{parinelloBarostat2} was used, because it samples the phase space more accurately. This barostat allows also a rotation of the position vectors. The appropriate matrix follows a differential equation depending on the current deviation of the pressure from the external pressure. However, large deviations lead to oscillations in the box \autocite[p. 36]{gromacsManual}.\\
\\
\gromacs{} provides the possibility to couple the z-direction independently from the x- and y-direction, which is called semiisotropic pressure coupling. This feature is useful for membrane and pulling simulations, because the dynamics differ a lot between these axes \autocite[p. 36]{gromacsManual}.